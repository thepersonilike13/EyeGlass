{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:30:10.327951Z",
     "start_time": "2024-02-26T17:30:06.702568Z"
    }
   },
   "id": "e2576852638ab639",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = YOLO('yolov8m.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:30:10.456133Z",
     "start_time": "2024-02-26T17:30:10.331360Z"
    }
   },
   "id": "ee551e138e8eac8e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/kausik/PycharmProjects/EyeGlass/Yolo Object Detection/bus.jpg: 640x480 4 persons, 1 bus, 378.4ms\n",
      "Speed: 3.8ms preprocess, 378.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "results = model('https://ultralytics.com/images/bus.jpg',show=True)  # predict on an image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:26:53.478639Z",
     "start_time": "2024-02-26T17:26:50.394766Z"
    }
   },
   "id": "cddea1bfc90d58ba",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 person, 297.8ms\n",
      "Speed: 4.1ms preprocess, 297.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 263.1ms\n",
      "Speed: 2.6ms preprocess, 263.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 265.5ms\n",
      "Speed: 1.6ms preprocess, 265.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 261.6ms\n",
      "Speed: 1.7ms preprocess, 261.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 251.5ms\n",
      "Speed: 2.1ms preprocess, 251.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 248.9ms\n",
      "Speed: 1.5ms preprocess, 248.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 248.3ms\n",
      "Speed: 2.0ms preprocess, 248.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 247.3ms\n",
      "Speed: 1.4ms preprocess, 247.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 250.9ms\n",
      "Speed: 2.7ms preprocess, 250.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 248.1ms\n",
      "Speed: 2.3ms preprocess, 248.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 245.4ms\n",
      "Speed: 1.6ms preprocess, 245.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 244.6ms\n",
      "Speed: 1.6ms preprocess, 244.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 251.4ms\n",
      "Speed: 2.1ms preprocess, 251.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 251.7ms\n",
      "Speed: 1.5ms preprocess, 251.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 253.3ms\n",
      "Speed: 3.1ms preprocess, 253.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 246.0ms\n",
      "Speed: 1.4ms preprocess, 246.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 250.8ms\n",
      "Speed: 2.9ms preprocess, 250.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 247.3ms\n",
      "Speed: 2.5ms preprocess, 247.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 248.6ms\n",
      "Speed: 2.6ms preprocess, 248.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 250.6ms\n",
      "Speed: 1.7ms preprocess, 250.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 277.2ms\n",
      "Speed: 1.3ms preprocess, 277.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 273.4ms\n",
      "Speed: 1.6ms preprocess, 273.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 258.4ms\n",
      "Speed: 1.4ms preprocess, 258.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 258.1ms\n",
      "Speed: 1.8ms preprocess, 258.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 255.2ms\n",
      "Speed: 1.5ms preprocess, 255.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 person, 1 clock, 250.8ms\n",
      "Speed: 1.6ms preprocess, 250.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "start = time.time()\n",
    "\n",
    "while time.time() - start < 10:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    results = model.predict(frame,show=True)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "\n",
    "# results = model.predict(source=frame,show=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:30:21.909291Z",
     "start_time": "2024-02-26T17:30:10.706918Z"
    }
   },
   "id": "d4631a8c55e93d90",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "536e1759e7b15771"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
