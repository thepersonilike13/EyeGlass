{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q roboflow \n!pip install -q ultralytics\n!pip install -q torch\n!pip install -q wandb\n!pip install -q torchvision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nsecret_label = \"RoboFlowAPI\"\nRoboFlowAPI = UserSecretsClient().get_secret(secret_label)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:15.562452Z","iopub.execute_input":"2024-02-22T03:40:15.562943Z","iopub.status.idle":"2024-02-22T03:40:15.698968Z","shell.execute_reply.started":"2024-02-22T03:40:15.562900Z","shell.execute_reply":"2024-02-22T03:40:15.698241Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/datasets\n%cd /kaggle/working/datasets","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:17.570981Z","iopub.execute_input":"2024-02-22T03:40:17.571816Z","iopub.status.idle":"2024-02-22T03:40:18.523535Z","shell.execute_reply.started":"2024-02-22T03:40:17.571784Z","shell.execute_reply":"2024-02-22T03:40:18.522216Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/datasets\n","output_type":"stream"}]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:19.133881Z","iopub.execute_input":"2024-02-22T03:40:19.134815Z","iopub.status.idle":"2024-02-22T03:40:19.142059Z","shell.execute_reply.started":"2024-02-22T03:40:19.134777Z","shell.execute_reply":"2024-02-22T03:40:19.141240Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/datasets'"},"metadata":{}}]},{"cell_type":"code","source":"from roboflow import Roboflow\nrf = Roboflow(api_key=RoboFlowAPI)\nproject = rf.workspace(\"sign-recognintion\").project(\"sign-recoginition\")\ndataset = project.version(1).download(\"yolov8-obb\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:21.668573Z","iopub.execute_input":"2024-02-22T03:40:21.669416Z","iopub.status.idle":"2024-02-22T03:40:29.862403Z","shell.execute_reply.started":"2024-02-22T03:40:21.669381Z","shell.execute_reply":"2024-02-22T03:40:29.861423Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"loading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in Sign-recoginition-1 to yolov8-obb:: 100%|██████████| 148516/148516 [00:04<00:00, 34747.53it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to Sign-recoginition-1 in yolov8-obb:: 100%|██████████| 9862/9862 [00:01<00:00, 8105.36it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"import yaml\n\nwith open(\"/kaggle/working/datasets/Sign-recoginition-1/data.yaml\",\"r\") as f:\n    data = yaml.safe_load(f)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:43.589010Z","iopub.execute_input":"2024-02-22T03:40:43.589484Z","iopub.status.idle":"2024-02-22T03:40:43.601715Z","shell.execute_reply.started":"2024-02-22T03:40:43.589453Z","shell.execute_reply":"2024-02-22T03:40:43.600733Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/datasets/Sign-recoginition-1/README.dataset.txt\",\"r\") as f:\n    content = f.read()\n\n    \nprint(content)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:44.935814Z","iopub.execute_input":"2024-02-22T03:40:44.936189Z","iopub.status.idle":"2024-02-22T03:40:44.941942Z","shell.execute_reply.started":"2024-02-22T03:40:44.936162Z","shell.execute_reply":"2024-02-22T03:40:44.940888Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"# Sign recoginition > 2023-03-03 5:34pm\nhttps://universe.roboflow.com/sign-recognintion/sign-recoginition\n\nProvided by a Roboflow user\nLicense: CC BY 4.0\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:48.181441Z","iopub.execute_input":"2024-02-22T03:40:48.182300Z","iopub.status.idle":"2024-02-22T03:40:48.189941Z","shell.execute_reply.started":"2024-02-22T03:40:48.182266Z","shell.execute_reply":"2024-02-22T03:40:48.188847Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'path': '../datasets/roboflow',\n 'train': 'train/images',\n 'val': 'valid/images',\n 'test': 'test/images',\n 'names': {0: 1,\n  1: 2,\n  2: 3,\n  3: 4,\n  4: 5,\n  5: 6,\n  6: 7,\n  7: 8,\n  8: 9,\n  9: 'A',\n  10: 'B',\n  11: 'C',\n  12: 'D',\n  13: 'E',\n  14: 'ExcuseMe',\n  15: 'F',\n  16: 'Food',\n  17: 'G',\n  18: 'H',\n  19: 'Hello',\n  20: 'Help',\n  21: 'House',\n  22: 'I',\n  23: 'I Love You',\n  24: 'Internet',\n  25: 'J',\n  26: 'K',\n  27: 'L',\n  28: 'M',\n  29: 'N',\n  30: False,\n  31: 'O',\n  32: 'P',\n  33: 'Please',\n  34: 'Q',\n  35: 'R',\n  36: 'S',\n  37: 'T',\n  38: 'ThankYou',\n  39: 'U',\n  40: 'V',\n  41: 'W',\n  42: 'X',\n  43: 'Y',\n  44: True,\n  45: 'Z'}}"},"metadata":{}}]},{"cell_type":"code","source":"data['path'] = \"/kaggle/working/datasets/Sign-recoginition-1\"","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:53.197529Z","iopub.execute_input":"2024-02-22T03:40:53.197880Z","iopub.status.idle":"2024-02-22T03:40:53.202175Z","shell.execute_reply.started":"2024-02-22T03:40:53.197851Z","shell.execute_reply":"2024-02-22T03:40:53.201136Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/datasets/Sign-recoginition-1/data.yaml","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:56.465646Z","iopub.execute_input":"2024-02-22T03:40:56.466025Z","iopub.status.idle":"2024-02-22T03:40:57.419150Z","shell.execute_reply.started":"2024-02-22T03:40:56.465996Z","shell.execute_reply":"2024-02-22T03:40:57.418020Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/datasets/Sign-recoginition-1/data.yaml\",\"w\") as f:\n    yaml.dump(data,f)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:57.597955Z","iopub.execute_input":"2024-02-22T03:40:57.598299Z","iopub.status.idle":"2024-02-22T03:40:57.607323Z","shell.execute_reply.started":"2024-02-22T03:40:57.598268Z","shell.execute_reply":"2024-02-22T03:40:57.606562Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!wandb login --verify \"YOUR_API_KEY\"","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:41:00.448608Z","iopub.execute_input":"2024-02-22T03:41:00.449305Z","iopub.status.idle":"2024-02-22T03:41:04.815547Z","shell.execute_reply.started":"2024-02-22T03:41:00.449269Z","shell.execute_reply":"2024-02-22T03:41:04.814591Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO(\"yolov8x-obb.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:41:17.599440Z","iopub.execute_input":"2024-02-22T03:41:17.599832Z","iopub.status.idle":"2024-02-22T03:41:30.149611Z","shell.execute_reply.started":"2024-02-22T03:41:17.599799Z","shell.execute_reply":"2024-02-22T03:41:30.148627Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x-obb.pt to 'yolov8x-obb.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 133M/133M [00:00<00:00, 170MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"model.train(\n    data=\"/kaggle/working/datasets/Sign-recoginition-1/data.yaml\", \n    epochs=50,\n    imgsz=640,\n    workers=32,\n    batch=32,\n    cache=True,\n    device=[0, 1],\n    name=\"First Run on Roboflow\",\n    save=True,\n    optimizer='AdamW',\n    cos_lr=True,\n    amp=True,\n    lr0=0.001,\n    lrf=0.02,\n    weight_decay=0.0005,\n    verbose=True,\n    val=True,\n    plots=True,\n    pretrained=\"yolov8x-obb.pt\",\n    dropout=0.15\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:43:21.791583Z","iopub.execute_input":"2024-02-22T03:43:21.792531Z","iopub.status.idle":"2024-02-22T06:24:10.340490Z","shell.execute_reply.started":"2024-02-22T03:43:21.792481Z","shell.execute_reply":"2024-02-22T06:24:10.339473Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.17 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolov8x-obb.pt, data=/kaggle/working/datasets/Sign-recoginition-1/data.yaml, epochs=50, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=True, device=[0, 1], workers=32, project=None, name=First Run on Roboflow, exist_ok=False, pretrained=yolov8x-obb.pt, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.15, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.02, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/obb/First Run on Roboflow\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 22        [15, 18, 21]  1  10088269  ultralytics.nn.modules.head.OBB              [46, 1, [320, 640, 640]]      \nYOLOv8x-obb summary: 390 layers, 69522909 parameters, 69522893 gradients, 264.1 GFLOPs\n\nTransferred 637/637 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 57631 /root/.config/Ultralytics/DDP/_temp_iqn4ggy0134576650891664.py\nUltralytics YOLOv8.1.17 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n","output_type":"stream"},{"name":"stderr","text":"2024-02-22 03:43:31.252006: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-22 03:43:31.252066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-22 03:43:31.253635: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/obb/First Run on Roboflow', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: kaus1kc0des (zer0ne). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.16.3 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.16.2\nwandb: Run data is saved locally in /kaggle/working/datasets/wandb/run-20240222_034334-q32yno69\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run First Run on Roboflow\nwandb: ⭐️ View project at https://wandb.ai/zer0ne/YOLOv8\nwandb: 🚀 View run at https://wandb.ai/zer0ne/YOLOv8/runs/q32yno69\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=15 with nc=46\nTransferred 631/637 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.23M/6.23M [00:00<00:00, 68.9MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/Sign-recoginition-1/train/labels... 4289 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4289/4289 [00:04<00:00, 973.10it/s] \n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/Sign-recoginition-1/train/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.9GB True): 100%|██████████| 4289/4289 [00:10<00:00, 404.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/Sign-recoginition-1/valid/labels... 414 images, 0 backgrounds, 0 corrupt: 100%|██████████| 414/414 [00:00<00:00, 1365.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/Sign-recoginition-1/valid/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB True): 100%|██████████| 414/414 [00:02<00:00, 181.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/obb/First Run on Roboflow/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 103 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/obb/First Run on Roboflow\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/50      14.2G      1.229      2.942      3.116          2        640: 100%|██████████| 135/135 [02:55<00:00,  1.30s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.733      0.464      0.605      0.419\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/50        15G      1.042      1.764      2.873          2        640: 100%|██████████| 135/135 [02:54<00:00,  1.30s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.724      0.827      0.899      0.705\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/50        15G     0.9501      1.437      2.755          2        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.787      0.755      0.874      0.665\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/50        15G     0.9076      1.284      2.672          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.811      0.783      0.889      0.719\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/50        15G     0.8442      1.114      2.613          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.925      0.888      0.936      0.793\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/50        15G     0.7803     0.9646       2.55          2        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.858      0.916      0.947      0.814\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/50        15G     0.7382     0.8806      2.504          2        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.893      0.916      0.944      0.797\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/50        15G     0.7402     0.8729      2.495          2        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.927      0.938      0.947      0.805\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/50      15.1G      0.698     0.8502      2.434          0        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.846       0.91      0.941      0.802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/50        15G     0.6832     0.7711      2.424          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.926      0.907      0.938      0.803\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/50        15G     0.6567      0.688      2.375          3        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.927      0.908      0.942      0.812\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/50        15G     0.6462     0.6955       2.33          0        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.848      0.905       0.95      0.781\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/50      15.1G     0.6459     0.6755      2.389          1        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.938      0.922      0.945      0.813\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/50        15G     0.6584     0.6852      2.387          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.889      0.949      0.951       0.82\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/50      15.1G     0.6223     0.6416      2.337          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414       0.94      0.945      0.956      0.835\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/50        15G     0.6085     0.6188      2.292          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414       0.93      0.926      0.956      0.828\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/50      15.1G     0.5879     0.5692      2.273          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.926      0.948      0.959      0.856\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/50        15G     0.5801     0.5675      2.267          3        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.909      0.932       0.95       0.85\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/50        15G     0.5715     0.5492      2.275          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.916      0.932      0.947      0.837\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/50        15G     0.5562     0.5335      2.256          1        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.961      0.914      0.947      0.839\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      21/50      15.1G     0.5585     0.5348      2.258          2        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.962      0.931      0.953      0.839\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      22/50        15G     0.5433     0.5199      2.257          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.945      0.927      0.942      0.832\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      23/50      15.1G     0.5204     0.4998       2.21          1        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.893      0.922      0.942      0.829\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      24/50        15G     0.5251     0.4838      2.218          2        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.909      0.958      0.963      0.858\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      26/50        15G     0.5217     0.4868       2.23          3        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414       0.88      0.947      0.959      0.855\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      27/50      15.1G     0.4863     0.4355       2.19          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.923      0.948      0.953      0.847\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      28/50        15G     0.4942     0.4483      2.162          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.946      0.942       0.96       0.87\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      29/50        15G     0.4862     0.4116      2.162          2        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.898      0.972      0.958      0.863\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      30/50        15G     0.4842     0.4243       2.17          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.942      0.926      0.955      0.851\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      31/50        15G     0.4773     0.4154      2.157          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.923      0.973      0.967      0.868\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      32/50        15G     0.4594        0.4      2.141          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.947      0.933      0.955      0.856\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      33/50        15G     0.4523      0.382      2.131          1        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414       0.89      0.941      0.942      0.852\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      34/50        15G     0.4533     0.3807      2.164          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.974       0.93      0.954      0.862\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      35/50      15.1G     0.4404     0.3718      2.151          3        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414       0.98      0.934      0.956      0.862\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      36/50        15G     0.4326     0.3558      2.137          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.946      0.944      0.952      0.859\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      37/50        15G      0.428     0.3576      2.124          3        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.966      0.937      0.956      0.867\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      38/50        15G     0.4231     0.3485      2.142          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.983      0.934      0.957      0.869\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      39/50        15G     0.4237     0.3485      2.119          4        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.972      0.935      0.951      0.864\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      40/50        15G     0.4119     0.3461      2.107          3        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.974      0.932      0.957      0.868\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      41/50        15G     0.2214     0.2403      1.931          1        640: 100%|██████████| 135/135 [02:52<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.986      0.932      0.953      0.867\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      42/50        15G     0.2059     0.2125      1.904          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.985      0.936      0.954      0.868\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      43/50        15G     0.1994     0.2599      1.862          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.989      0.932      0.945      0.863\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      44/50        15G     0.1907     0.2124      1.876          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414       0.99      0.935      0.948      0.868\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      45/50      15.1G     0.1848      0.202      1.889          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.988      0.935       0.95      0.866\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      46/50        15G     0.1816     0.1921      1.885          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.985      0.935      0.949      0.865\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      47/50        15G     0.1804     0.1942      1.849          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.989      0.935      0.947      0.874\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      48/50        15G      0.172     0.1858      1.862          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.988      0.935      0.946      0.874\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      49/50      15.1G     0.1694     0.1795      1.863          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.989      0.935      0.946      0.871\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      50/50        15G      0.162     0.1782      1.856          1        640: 100%|██████████| 135/135 [02:51<00:00,  1.27s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:13<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.987      0.934      0.946      0.871\n\n50 epochs completed in 2.647 hours.\nOptimizer stripped from runs/obb/First Run on Roboflow/weights/last.pt, 139.7MB\nOptimizer stripped from runs/obb/First Run on Roboflow/weights/best.pt, 139.7MB\n\nValidating runs/obb/First Run on Roboflow/weights/best.pt...\nUltralytics YOLOv8.1.17 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\nYOLOv8x-obb summary (fused): 287 layers, 69493389 parameters, 0 gradients, 263.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:15<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        414        414      0.989      0.935      0.947      0.874\n                     1        414         10      0.986          1      0.995      0.891\n                     2        414         10      0.985          1      0.995      0.931\n                     3        414         10          1          1      0.995      0.945\n                     4        414         10          1          1      0.995      0.978\n                     5        414         10      0.986          1      0.995      0.922\n                     6        414         10          1          1      0.995      0.901\n                     7        414         10          1          1      0.995      0.924\n                     8        414         10          1          1      0.995      0.981\n                     9        414         10          1          1      0.995       0.92\n                     A        414         10          1          1      0.995      0.974\n                     B        414         10          1          1      0.995      0.923\n                     C        414         10          1          1      0.995      0.914\n                     D        414         10          1          1      0.995      0.932\n                     E        414         10      0.986          1      0.995      0.954\n              ExcuseMe        414          7          1          1      0.995      0.987\n                     F        414         10      0.983          1      0.995      0.934\n                  Food        414         12          1          1      0.995       0.98\n                     G        414         10          1          1      0.995      0.892\n                     H        414         10      0.983          1      0.995       0.94\n                 Hello        414         12          1      0.921      0.995      0.921\n                  Help        414          1          1          0          0          0\n                 House        414          4          1          0          0          0\n                     I        414          9          1          1      0.995      0.896\n            I Love You        414          7          1      0.483      0.978      0.752\n              Internet        414          6          1          1      0.995      0.995\n                     J        414         10      0.984          1      0.995      0.954\n                     K        414         10          1          1      0.995      0.961\n                     L        414         10      0.983          1      0.995      0.972\n                     M        414         10       0.99          1      0.995      0.885\n                     N        414         10      0.995          1      0.995       0.96\n                 False        414          2          1          1      0.995      0.895\n                     O        414         10      0.991          1      0.995      0.914\n                     P        414         10          1          1      0.995      0.968\n                Please        414          5      0.841        0.6      0.777      0.524\n                     Q        414         10          1          1      0.995      0.869\n                     R        414         10      0.984          1      0.995      0.928\n                     S        414         10      0.985          1      0.995      0.957\n                     T        414         10      0.985          1      0.995      0.962\n              ThankYou        414          8      0.992          1      0.995      0.985\n                     U        414         10          1          1      0.995      0.926\n                     V        414         10      0.986          1      0.995       0.92\n                     W        414         10          1          1      0.995      0.936\n                     X        414         10          1          1      0.995      0.936\n                     Y        414         10       0.99          1      0.995      0.871\n                  True        414          1      0.907          1      0.995      0.597\n                     Z        414         10      0.984          1      0.995      0.889\nSpeed: 0.2ms preprocess, 26.0ms inference, 0.0ms loss, 3.7ms postprocess per image\nResults saved to \u001b[1mruns/obb/First Run on Roboflow\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"wandb:                                                                                \nwandb: \nwandb: Run history:\nwandb:                  lr/pg0 █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\nwandb:                  lr/pg1 ▃▆██████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\nwandb:                  lr/pg2 ▃▆██████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\nwandb:        metrics/mAP50(B) ▁▇▆▇████████████████████████████████████\nwandb:     metrics/mAP50-95(B) ▁▅▅▆▇▇▇▇▇▇▇▇▇██▇▇▇▇█████████████████████\nwandb:    metrics/precision(B) ▁▁▃▃▅▅▆▄▆▄▇▅▆▆▆▆▇▇▅▆▅▆▇▆▆▇▅█▇▇██████████\nwandb:       metrics/recall(B) ▁▆▅▅▇▇█▇▇��▇█▇█▇▇▇▇▇██████▇█▇█▇▇▇▇▇▇▇▇▇▇▇\nwandb:            model/GFLOPs ▁\nwandb:        model/parameters ▁\nwandb: model/speed_PyTorch(ms) ▁\nwandb:          train/box_loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁\nwandb:          train/cls_loss █▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\nwandb:          train/dfl_loss █▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▁▁▁▁▁▁▁▁\nwandb:            val/box_loss █▄▅▄▂▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\nwandb:            val/cls_loss █▃▃▂▁▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\nwandb:            val/dfl_loss █▆▇▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▂▁▂▂▁▁▁\nwandb: \nwandb: Run summary:\nwandb:                  lr/pg0 2e-05\nwandb:                  lr/pg1 2e-05\nwandb:                  lr/pg2 2e-05\nwandb:        metrics/mAP50(B) 0.94662\nwandb:     metrics/mAP50-95(B) 0.87388\nwandb:    metrics/precision(B) 0.98927\nwandb:       metrics/recall(B) 0.93488\nwandb:            model/GFLOPs 264.137\nwandb:        model/parameters 69522909\nwandb: model/speed_PyTorch(ms) 26.731\nwandb:          train/box_loss 0.16202\nwandb:          train/cls_loss 0.17819\nwandb:          train/dfl_loss 1.85594\nwandb:            val/box_loss 0.43537\nwandb:            val/cls_loss 0.27448\nwandb:            val/dfl_loss 2.48451\nwandb: \nwandb: 🚀 View run First Run on Roboflow at: https://wandb.ai/zer0ne/YOLOv8/runs/q32yno69\nwandb: Synced 6 W&B file(s), 20 media file(s), 1 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20240222_034334-q32yno69/logs\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"/kaggle/working/working_model_sign_lang_detect.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:02:55.989309Z","iopub.execute_input":"2024-02-22T12:02:55.989647Z","iopub.status.idle":"2024-02-22T12:02:56.013409Z","shell.execute_reply.started":"2024-02-22T12:02:55.989623Z","shell.execute_reply":"2024-02-22T12:02:56.012128Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mmodel\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"model.export(format=\"onnx\", verbose=True)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.export(format=\"saved_model\",keras=True, verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.export(format=\"torchscript\", verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:04:10.961206Z","iopub.execute_input":"2024-02-22T12:04:10.961855Z","iopub.status.idle":"2024-02-22T12:04:11.330159Z","shell.execute_reply.started":"2024-02-22T12:04:10.961824Z","shell.execute_reply":"2024-02-22T12:04:11.329277Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/datasets/runs/obb/First Run on Roboflow/results.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:04:24.409509Z","iopub.execute_input":"2024-02-22T12:04:24.409944Z","iopub.status.idle":"2024-02-22T12:04:24.423012Z","shell.execute_reply.started":"2024-02-22T12:04:24.409910Z","shell.execute_reply":"2024-02-22T12:04:24.421993Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:04:26.908429Z","iopub.execute_input":"2024-02-22T12:04:26.909423Z","iopub.status.idle":"2024-02-22T12:04:26.973559Z","shell.execute_reply.started":"2024-02-22T12:04:26.909362Z","shell.execute_reply":"2024-02-22T12:04:26.972619Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                   epoch        train/box_loss        train/cls_loss  \\\n0                      1               1.22880               2.94240   \n1                      2               1.04230               1.76380   \n2                      3               0.95007               1.43670   \n3                      4               0.90760               1.28450   \n4                      5               0.84423               1.11390   \n5                      6               0.78033               0.96463   \n6                      7               0.73824               0.88061   \n7                      8               0.74022               0.87285   \n8                      9               0.69802               0.85022   \n9                     10               0.68316               0.77106   \n10                    11               0.65673               0.68797   \n11                    12               0.64621               0.69547   \n12                    13               0.64594               0.67547   \n13                    14               0.65840               0.68521   \n14                    15               0.62233               0.64157   \n15                    16               0.60846               0.61881   \n16                    17               0.58791               0.56920   \n17                    18               0.58006               0.56747   \n18                    19               0.57154               0.54922   \n19                    20               0.55617               0.53351   \n20                    21               0.55845               0.53482   \n21                    22               0.54329               0.51992   \n22                    23               0.52037               0.49976   \n23                    24               0.52506               0.48377   \n24                    25               0.51766               0.48245   \n25                    26               0.52168               0.48680   \n26                    27               0.48628               0.43552   \n27                    28               0.49425               0.44831   \n28                    29               0.48620               0.41163   \n29                    30               0.48416               0.42432   \n30                    31               0.47732               0.41535   \n31                    32               0.45936               0.40003   \n32                    33               0.45226               0.38198   \n33                    34               0.45330               0.38067   \n34                    35               0.44036               0.37183   \n35                    36               0.43255               0.35575   \n36                    37               0.42804               0.35761   \n37                    38               0.42308               0.34851   \n38                    39               0.42371               0.34850   \n39                    40               0.41193               0.34613   \n40                    41               0.22143               0.24027   \n41                    42               0.20593               0.21253   \n42                    43               0.19943               0.25987   \n43                    44               0.19073               0.21239   \n44                    45               0.18484               0.20205   \n45                    46               0.18160               0.19207   \n46                    47               0.18038               0.19424   \n47                    48               0.17204               0.18580   \n48                    49               0.16945               0.17955   \n49                    50               0.16202               0.17819   \n\n          train/dfl_loss  metrics/precision(B)     metrics/recall(B)  \\\n0                 3.1158               0.73349               0.46403   \n1                 2.8727               0.72387               0.82662   \n2                 2.7545               0.78732               0.75461   \n3                 2.6719               0.81072               0.78290   \n4                 2.6134               0.92483               0.88770   \n5                 2.5503               0.85833               0.91601   \n6                 2.5041               0.89332               0.91570   \n7                 2.4946               0.92693               0.93771   \n8                 2.4339               0.84578               0.91008   \n9                 2.4237               0.92626               0.90666   \n10                2.3746               0.92650               0.90755   \n11                2.3303               0.84828               0.90475   \n12                2.3892               0.93760               0.92246   \n13                2.3873               0.88929               0.94885   \n14                2.3365               0.94026               0.94526   \n15                2.2921               0.93007               0.92586   \n16                2.2734               0.92556               0.94776   \n17                2.2674               0.90919               0.93187   \n18                2.2747               0.91632               0.93199   \n19                2.2565               0.96077               0.91366   \n20                2.2577               0.96216               0.93090   \n21                2.2573               0.94525               0.92744   \n22                2.2101               0.89312               0.92240   \n23                2.2177               0.90888               0.95759   \n24                2.2092               0.95279               0.92164   \n25                2.2299               0.87976               0.94678   \n26                2.1900               0.92300               0.94766   \n27                2.1623               0.94569               0.94224   \n28                2.1622               0.89776               0.97210   \n29                2.1703               0.94238               0.92634   \n30                2.1566               0.92349               0.97334   \n31                2.1405               0.94705               0.93292   \n32                2.1305               0.88964               0.94100   \n33                2.1636               0.97441               0.93016   \n34                2.1508               0.98018               0.93416   \n35                2.1374               0.94597               0.94397   \n36                2.1237               0.96565               0.93688   \n37                2.1415               0.98261               0.93429   \n38                2.1192               0.97221               0.93512   \n39                2.1065               0.97382               0.93233   \n40                1.9313               0.98562               0.93228   \n41                1.9041               0.98457               0.93641   \n42                1.8619               0.98911               0.93182   \n43                1.8758               0.99039               0.93464   \n44                1.8885               0.98763               0.93480   \n45                1.8845               0.98490               0.93465   \n46                1.8495               0.98927               0.93489   \n47                1.8620               0.98814               0.93477   \n48                1.8630               0.98853               0.93472   \n49                1.8559               0.98728               0.93418   \n\n        metrics/mAP50(B)   metrics/mAP50-95(B)          val/box_loss  \\\n0                0.60452               0.41858               1.20780   \n1                0.89931               0.70522               0.80162   \n2                0.87405               0.66481               0.92753   \n3                0.88944               0.71900               0.77751   \n4                0.93628               0.79327               0.68564   \n5                0.94719               0.81417               0.59877   \n6                0.94387               0.79671               0.69146   \n7                0.94709               0.80540               0.62603   \n8                0.94149               0.80238               0.63249   \n9                0.93801               0.80309               0.63774   \n10               0.94215               0.81179               0.60397   \n11               0.95016               0.78106               0.65815   \n12               0.94456               0.81318               0.60286   \n13               0.95108               0.81973               0.57520   \n14               0.95642               0.83494               0.54621   \n15               0.95567               0.82762               0.57125   \n16               0.95920               0.85559               0.52259   \n17               0.95043               0.84965               0.51198   \n18               0.94650               0.83719               0.51450   \n19               0.94688               0.83903               0.54269   \n20               0.95275               0.83902               0.53203   \n21               0.94191               0.83185               0.51885   \n22               0.94238               0.82926               0.53444   \n23               0.96299               0.85843               0.48641   \n24               0.94284               0.84250               0.51375   \n25               0.95867               0.85469               0.51392   \n26               0.95251               0.84690               0.52357   \n27               0.95969               0.86969               0.46923   \n28               0.95819               0.86323               0.49045   \n29               0.95483               0.85123               0.49703   \n30               0.96652               0.86842               0.47184   \n31               0.95472               0.85582               0.48643   \n32               0.94175               0.85234               0.47217   \n33               0.95416               0.86218               0.47491   \n34               0.95573               0.86247               0.49807   \n35               0.95241               0.85919               0.47015   \n36               0.95629               0.86699               0.45062   \n37               0.95697               0.86941               0.44203   \n38               0.95123               0.86431               0.45941   \n39               0.95681               0.86788               0.45534   \n40               0.95272               0.86732               0.45240   \n41               0.95357               0.86813               0.45710   \n42               0.94511               0.86255               0.45248   \n43               0.94798               0.86752               0.44919   \n44               0.95019               0.86592               0.44724   \n45               0.94868               0.86513               0.45292   \n46               0.94662               0.87385               0.44193   \n47               0.94561               0.87355               0.43602   \n48               0.94627               0.87112               0.43723   \n49               0.94551               0.87090               0.43537   \n\n            val/cls_loss          val/dfl_loss                lr/pg0  \\\n0                4.01490                3.2571              0.067244   \n1                1.19430                3.0112              0.034244   \n2                1.24840                3.0975              0.001241   \n3                0.97803                2.9684              0.000991   \n4                0.58113                2.8666              0.000991   \n5                0.53961                2.7588              0.000985   \n6                0.52226                2.7541              0.000976   \n7                0.52880                2.7792              0.000966   \n8                0.70420                2.8202              0.000953   \n9                0.50222                2.8212              0.000939   \n10               0.45776                2.7812              0.000924   \n11               0.59429                2.7280              0.000906   \n12               0.42061                2.6922              0.000888   \n13               0.54860                2.6975              0.000867   \n14               0.40653                2.5806              0.000845   \n15               0.48249                2.6756              0.000822   \n16               0.35352                2.5809              0.000798   \n17               0.42427                2.5633              0.000773   \n18               0.39851                2.5794              0.000746   \n19               0.38482                2.5376              0.000719   \n20               0.38463                2.5472              0.000690   \n21               0.41677                2.5485              0.000661   \n22               0.47305                2.5797              0.000632   \n23               0.35968                2.5473              0.000602   \n24               0.36634                2.5575              0.000571   \n25               0.38097                2.5433              0.000541   \n26               0.39289                2.6151              0.000510   \n27               0.32170                2.5124              0.000479   \n28               0.32722                2.5082              0.000449   \n29               0.32235                2.5230              0.000418   \n30               0.32920                2.5193              0.000388   \n31               0.31574                2.4881              0.000359   \n32               0.35720                2.5042              0.000330   \n33               0.31769                2.4917              0.000301   \n34               0.31990                2.5746              0.000274   \n35               0.31731                2.4568              0.000247   \n36               0.30135                2.4947              0.000222   \n37               0.28305                2.4908              0.000198   \n38               0.29582                2.5070              0.000175   \n39               0.28002                2.4850              0.000153   \n40               0.29545                2.5076              0.000132   \n41               0.28467                2.5179              0.000114   \n42               0.29214                2.4881              0.000096   \n43               0.28252                2.5230              0.000081   \n44               0.28675                2.5194              0.000067   \n45               0.29405                2.5296              0.000054   \n46               0.28230                2.5060              0.000044   \n47               0.28210                2.4859              0.000035   \n48               0.28163                2.5015              0.000029   \n49               0.27448                2.4845              0.000024   \n\n                  lr/pg1                lr/pg2  \n0               0.000331              0.000331  \n1               0.000664              0.000664  \n2               0.000994              0.000994  \n3               0.000991              0.000991  \n4               0.000991              0.000991  \n5               0.000985              0.000985  \n6               0.000976              0.000976  \n7               0.000966              0.000966  \n8               0.000953              0.000953  \n9               0.000939              0.000939  \n10              0.000924              0.000924  \n11              0.000906              0.000906  \n12              0.000888              0.000888  \n13              0.000867              0.000867  \n14              0.000845              0.000845  \n15              0.000822              0.000822  \n16              0.000798              0.000798  \n17              0.000773              0.000773  \n18              0.000746              0.000746  \n19              0.000719              0.000719  \n20              0.000690              0.000690  \n21              0.000661              0.000661  \n22              0.000632              0.000632  \n23              0.000602              0.000602  \n24              0.000571              0.000571  \n25              0.000541              0.000541  \n26              0.000510              0.000510  \n27              0.000479              0.000479  \n28              0.000449              0.000449  \n29              0.000418              0.000418  \n30              0.000388              0.000388  \n31              0.000359              0.000359  \n32              0.000330              0.000330  \n33              0.000301              0.000301  \n34              0.000274              0.000274  \n35              0.000247              0.000247  \n36              0.000222              0.000222  \n37              0.000198              0.000198  \n38              0.000175              0.000175  \n39              0.000153              0.000153  \n40              0.000132              0.000132  \n41              0.000114              0.000114  \n42              0.000096              0.000096  \n43              0.000081              0.000081  \n44              0.000067              0.000067  \n45              0.000054              0.000054  \n46              0.000044              0.000044  \n47              0.000035              0.000035  \n48              0.000029              0.000029  \n49              0.000024              0.000024  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>train/box_loss</th>\n      <th>train/cls_loss</th>\n      <th>train/dfl_loss</th>\n      <th>metrics/precision(B)</th>\n      <th>metrics/recall(B)</th>\n      <th>metrics/mAP50(B)</th>\n      <th>metrics/mAP50-95(B)</th>\n      <th>val/box_loss</th>\n      <th>val/cls_loss</th>\n      <th>val/dfl_loss</th>\n      <th>lr/pg0</th>\n      <th>lr/pg1</th>\n      <th>lr/pg2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.22880</td>\n      <td>2.94240</td>\n      <td>3.1158</td>\n      <td>0.73349</td>\n      <td>0.46403</td>\n      <td>0.60452</td>\n      <td>0.41858</td>\n      <td>1.20780</td>\n      <td>4.01490</td>\n      <td>3.2571</td>\n      <td>0.067244</td>\n      <td>0.000331</td>\n      <td>0.000331</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.04230</td>\n      <td>1.76380</td>\n      <td>2.8727</td>\n      <td>0.72387</td>\n      <td>0.82662</td>\n      <td>0.89931</td>\n      <td>0.70522</td>\n      <td>0.80162</td>\n      <td>1.19430</td>\n      <td>3.0112</td>\n      <td>0.034244</td>\n      <td>0.000664</td>\n      <td>0.000664</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.95007</td>\n      <td>1.43670</td>\n      <td>2.7545</td>\n      <td>0.78732</td>\n      <td>0.75461</td>\n      <td>0.87405</td>\n      <td>0.66481</td>\n      <td>0.92753</td>\n      <td>1.24840</td>\n      <td>3.0975</td>\n      <td>0.001241</td>\n      <td>0.000994</td>\n      <td>0.000994</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.90760</td>\n      <td>1.28450</td>\n      <td>2.6719</td>\n      <td>0.81072</td>\n      <td>0.78290</td>\n      <td>0.88944</td>\n      <td>0.71900</td>\n      <td>0.77751</td>\n      <td>0.97803</td>\n      <td>2.9684</td>\n      <td>0.000991</td>\n      <td>0.000991</td>\n      <td>0.000991</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.84423</td>\n      <td>1.11390</td>\n      <td>2.6134</td>\n      <td>0.92483</td>\n      <td>0.88770</td>\n      <td>0.93628</td>\n      <td>0.79327</td>\n      <td>0.68564</td>\n      <td>0.58113</td>\n      <td>2.8666</td>\n      <td>0.000991</td>\n      <td>0.000991</td>\n      <td>0.000991</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.78033</td>\n      <td>0.96463</td>\n      <td>2.5503</td>\n      <td>0.85833</td>\n      <td>0.91601</td>\n      <td>0.94719</td>\n      <td>0.81417</td>\n      <td>0.59877</td>\n      <td>0.53961</td>\n      <td>2.7588</td>\n      <td>0.000985</td>\n      <td>0.000985</td>\n      <td>0.000985</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.73824</td>\n      <td>0.88061</td>\n      <td>2.5041</td>\n      <td>0.89332</td>\n      <td>0.91570</td>\n      <td>0.94387</td>\n      <td>0.79671</td>\n      <td>0.69146</td>\n      <td>0.52226</td>\n      <td>2.7541</td>\n      <td>0.000976</td>\n      <td>0.000976</td>\n      <td>0.000976</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.74022</td>\n      <td>0.87285</td>\n      <td>2.4946</td>\n      <td>0.92693</td>\n      <td>0.93771</td>\n      <td>0.94709</td>\n      <td>0.80540</td>\n      <td>0.62603</td>\n      <td>0.52880</td>\n      <td>2.7792</td>\n      <td>0.000966</td>\n      <td>0.000966</td>\n      <td>0.000966</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.69802</td>\n      <td>0.85022</td>\n      <td>2.4339</td>\n      <td>0.84578</td>\n      <td>0.91008</td>\n      <td>0.94149</td>\n      <td>0.80238</td>\n      <td>0.63249</td>\n      <td>0.70420</td>\n      <td>2.8202</td>\n      <td>0.000953</td>\n      <td>0.000953</td>\n      <td>0.000953</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.68316</td>\n      <td>0.77106</td>\n      <td>2.4237</td>\n      <td>0.92626</td>\n      <td>0.90666</td>\n      <td>0.93801</td>\n      <td>0.80309</td>\n      <td>0.63774</td>\n      <td>0.50222</td>\n      <td>2.8212</td>\n      <td>0.000939</td>\n      <td>0.000939</td>\n      <td>0.000939</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.65673</td>\n      <td>0.68797</td>\n      <td>2.3746</td>\n      <td>0.92650</td>\n      <td>0.90755</td>\n      <td>0.94215</td>\n      <td>0.81179</td>\n      <td>0.60397</td>\n      <td>0.45776</td>\n      <td>2.7812</td>\n      <td>0.000924</td>\n      <td>0.000924</td>\n      <td>0.000924</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.64621</td>\n      <td>0.69547</td>\n      <td>2.3303</td>\n      <td>0.84828</td>\n      <td>0.90475</td>\n      <td>0.95016</td>\n      <td>0.78106</td>\n      <td>0.65815</td>\n      <td>0.59429</td>\n      <td>2.7280</td>\n      <td>0.000906</td>\n      <td>0.000906</td>\n      <td>0.000906</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.64594</td>\n      <td>0.67547</td>\n      <td>2.3892</td>\n      <td>0.93760</td>\n      <td>0.92246</td>\n      <td>0.94456</td>\n      <td>0.81318</td>\n      <td>0.60286</td>\n      <td>0.42061</td>\n      <td>2.6922</td>\n      <td>0.000888</td>\n      <td>0.000888</td>\n      <td>0.000888</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.65840</td>\n      <td>0.68521</td>\n      <td>2.3873</td>\n      <td>0.88929</td>\n      <td>0.94885</td>\n      <td>0.95108</td>\n      <td>0.81973</td>\n      <td>0.57520</td>\n      <td>0.54860</td>\n      <td>2.6975</td>\n      <td>0.000867</td>\n      <td>0.000867</td>\n      <td>0.000867</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.62233</td>\n      <td>0.64157</td>\n      <td>2.3365</td>\n      <td>0.94026</td>\n      <td>0.94526</td>\n      <td>0.95642</td>\n      <td>0.83494</td>\n      <td>0.54621</td>\n      <td>0.40653</td>\n      <td>2.5806</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>0.60846</td>\n      <td>0.61881</td>\n      <td>2.2921</td>\n      <td>0.93007</td>\n      <td>0.92586</td>\n      <td>0.95567</td>\n      <td>0.82762</td>\n      <td>0.57125</td>\n      <td>0.48249</td>\n      <td>2.6756</td>\n      <td>0.000822</td>\n      <td>0.000822</td>\n      <td>0.000822</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>0.58791</td>\n      <td>0.56920</td>\n      <td>2.2734</td>\n      <td>0.92556</td>\n      <td>0.94776</td>\n      <td>0.95920</td>\n      <td>0.85559</td>\n      <td>0.52259</td>\n      <td>0.35352</td>\n      <td>2.5809</td>\n      <td>0.000798</td>\n      <td>0.000798</td>\n      <td>0.000798</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>0.58006</td>\n      <td>0.56747</td>\n      <td>2.2674</td>\n      <td>0.90919</td>\n      <td>0.93187</td>\n      <td>0.95043</td>\n      <td>0.84965</td>\n      <td>0.51198</td>\n      <td>0.42427</td>\n      <td>2.5633</td>\n      <td>0.000773</td>\n      <td>0.000773</td>\n      <td>0.000773</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>0.57154</td>\n      <td>0.54922</td>\n      <td>2.2747</td>\n      <td>0.91632</td>\n      <td>0.93199</td>\n      <td>0.94650</td>\n      <td>0.83719</td>\n      <td>0.51450</td>\n      <td>0.39851</td>\n      <td>2.5794</td>\n      <td>0.000746</td>\n      <td>0.000746</td>\n      <td>0.000746</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>0.55617</td>\n      <td>0.53351</td>\n      <td>2.2565</td>\n      <td>0.96077</td>\n      <td>0.91366</td>\n      <td>0.94688</td>\n      <td>0.83903</td>\n      <td>0.54269</td>\n      <td>0.38482</td>\n      <td>2.5376</td>\n      <td>0.000719</td>\n      <td>0.000719</td>\n      <td>0.000719</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>0.55845</td>\n      <td>0.53482</td>\n      <td>2.2577</td>\n      <td>0.96216</td>\n      <td>0.93090</td>\n      <td>0.95275</td>\n      <td>0.83902</td>\n      <td>0.53203</td>\n      <td>0.38463</td>\n      <td>2.5472</td>\n      <td>0.000690</td>\n      <td>0.000690</td>\n      <td>0.000690</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>0.54329</td>\n      <td>0.51992</td>\n      <td>2.2573</td>\n      <td>0.94525</td>\n      <td>0.92744</td>\n      <td>0.94191</td>\n      <td>0.83185</td>\n      <td>0.51885</td>\n      <td>0.41677</td>\n      <td>2.5485</td>\n      <td>0.000661</td>\n      <td>0.000661</td>\n      <td>0.000661</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>0.52037</td>\n      <td>0.49976</td>\n      <td>2.2101</td>\n      <td>0.89312</td>\n      <td>0.92240</td>\n      <td>0.94238</td>\n      <td>0.82926</td>\n      <td>0.53444</td>\n      <td>0.47305</td>\n      <td>2.5797</td>\n      <td>0.000632</td>\n      <td>0.000632</td>\n      <td>0.000632</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>0.52506</td>\n      <td>0.48377</td>\n      <td>2.2177</td>\n      <td>0.90888</td>\n      <td>0.95759</td>\n      <td>0.96299</td>\n      <td>0.85843</td>\n      <td>0.48641</td>\n      <td>0.35968</td>\n      <td>2.5473</td>\n      <td>0.000602</td>\n      <td>0.000602</td>\n      <td>0.000602</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>0.51766</td>\n      <td>0.48245</td>\n      <td>2.2092</td>\n      <td>0.95279</td>\n      <td>0.92164</td>\n      <td>0.94284</td>\n      <td>0.84250</td>\n      <td>0.51375</td>\n      <td>0.36634</td>\n      <td>2.5575</td>\n      <td>0.000571</td>\n      <td>0.000571</td>\n      <td>0.000571</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>0.52168</td>\n      <td>0.48680</td>\n      <td>2.2299</td>\n      <td>0.87976</td>\n      <td>0.94678</td>\n      <td>0.95867</td>\n      <td>0.85469</td>\n      <td>0.51392</td>\n      <td>0.38097</td>\n      <td>2.5433</td>\n      <td>0.000541</td>\n      <td>0.000541</td>\n      <td>0.000541</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0.48628</td>\n      <td>0.43552</td>\n      <td>2.1900</td>\n      <td>0.92300</td>\n      <td>0.94766</td>\n      <td>0.95251</td>\n      <td>0.84690</td>\n      <td>0.52357</td>\n      <td>0.39289</td>\n      <td>2.6151</td>\n      <td>0.000510</td>\n      <td>0.000510</td>\n      <td>0.000510</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0.49425</td>\n      <td>0.44831</td>\n      <td>2.1623</td>\n      <td>0.94569</td>\n      <td>0.94224</td>\n      <td>0.95969</td>\n      <td>0.86969</td>\n      <td>0.46923</td>\n      <td>0.32170</td>\n      <td>2.5124</td>\n      <td>0.000479</td>\n      <td>0.000479</td>\n      <td>0.000479</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>0.48620</td>\n      <td>0.41163</td>\n      <td>2.1622</td>\n      <td>0.89776</td>\n      <td>0.97210</td>\n      <td>0.95819</td>\n      <td>0.86323</td>\n      <td>0.49045</td>\n      <td>0.32722</td>\n      <td>2.5082</td>\n      <td>0.000449</td>\n      <td>0.000449</td>\n      <td>0.000449</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>0.48416</td>\n      <td>0.42432</td>\n      <td>2.1703</td>\n      <td>0.94238</td>\n      <td>0.92634</td>\n      <td>0.95483</td>\n      <td>0.85123</td>\n      <td>0.49703</td>\n      <td>0.32235</td>\n      <td>2.5230</td>\n      <td>0.000418</td>\n      <td>0.000418</td>\n      <td>0.000418</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>0.47732</td>\n      <td>0.41535</td>\n      <td>2.1566</td>\n      <td>0.92349</td>\n      <td>0.97334</td>\n      <td>0.96652</td>\n      <td>0.86842</td>\n      <td>0.47184</td>\n      <td>0.32920</td>\n      <td>2.5193</td>\n      <td>0.000388</td>\n      <td>0.000388</td>\n      <td>0.000388</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>0.45936</td>\n      <td>0.40003</td>\n      <td>2.1405</td>\n      <td>0.94705</td>\n      <td>0.93292</td>\n      <td>0.95472</td>\n      <td>0.85582</td>\n      <td>0.48643</td>\n      <td>0.31574</td>\n      <td>2.4881</td>\n      <td>0.000359</td>\n      <td>0.000359</td>\n      <td>0.000359</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>0.45226</td>\n      <td>0.38198</td>\n      <td>2.1305</td>\n      <td>0.88964</td>\n      <td>0.94100</td>\n      <td>0.94175</td>\n      <td>0.85234</td>\n      <td>0.47217</td>\n      <td>0.35720</td>\n      <td>2.5042</td>\n      <td>0.000330</td>\n      <td>0.000330</td>\n      <td>0.000330</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34</td>\n      <td>0.45330</td>\n      <td>0.38067</td>\n      <td>2.1636</td>\n      <td>0.97441</td>\n      <td>0.93016</td>\n      <td>0.95416</td>\n      <td>0.86218</td>\n      <td>0.47491</td>\n      <td>0.31769</td>\n      <td>2.4917</td>\n      <td>0.000301</td>\n      <td>0.000301</td>\n      <td>0.000301</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35</td>\n      <td>0.44036</td>\n      <td>0.37183</td>\n      <td>2.1508</td>\n      <td>0.98018</td>\n      <td>0.93416</td>\n      <td>0.95573</td>\n      <td>0.86247</td>\n      <td>0.49807</td>\n      <td>0.31990</td>\n      <td>2.5746</td>\n      <td>0.000274</td>\n      <td>0.000274</td>\n      <td>0.000274</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>0.43255</td>\n      <td>0.35575</td>\n      <td>2.1374</td>\n      <td>0.94597</td>\n      <td>0.94397</td>\n      <td>0.95241</td>\n      <td>0.85919</td>\n      <td>0.47015</td>\n      <td>0.31731</td>\n      <td>2.4568</td>\n      <td>0.000247</td>\n      <td>0.000247</td>\n      <td>0.000247</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>37</td>\n      <td>0.42804</td>\n      <td>0.35761</td>\n      <td>2.1237</td>\n      <td>0.96565</td>\n      <td>0.93688</td>\n      <td>0.95629</td>\n      <td>0.86699</td>\n      <td>0.45062</td>\n      <td>0.30135</td>\n      <td>2.4947</td>\n      <td>0.000222</td>\n      <td>0.000222</td>\n      <td>0.000222</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>38</td>\n      <td>0.42308</td>\n      <td>0.34851</td>\n      <td>2.1415</td>\n      <td>0.98261</td>\n      <td>0.93429</td>\n      <td>0.95697</td>\n      <td>0.86941</td>\n      <td>0.44203</td>\n      <td>0.28305</td>\n      <td>2.4908</td>\n      <td>0.000198</td>\n      <td>0.000198</td>\n      <td>0.000198</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>39</td>\n      <td>0.42371</td>\n      <td>0.34850</td>\n      <td>2.1192</td>\n      <td>0.97221</td>\n      <td>0.93512</td>\n      <td>0.95123</td>\n      <td>0.86431</td>\n      <td>0.45941</td>\n      <td>0.29582</td>\n      <td>2.5070</td>\n      <td>0.000175</td>\n      <td>0.000175</td>\n      <td>0.000175</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>0.41193</td>\n      <td>0.34613</td>\n      <td>2.1065</td>\n      <td>0.97382</td>\n      <td>0.93233</td>\n      <td>0.95681</td>\n      <td>0.86788</td>\n      <td>0.45534</td>\n      <td>0.28002</td>\n      <td>2.4850</td>\n      <td>0.000153</td>\n      <td>0.000153</td>\n      <td>0.000153</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>41</td>\n      <td>0.22143</td>\n      <td>0.24027</td>\n      <td>1.9313</td>\n      <td>0.98562</td>\n      <td>0.93228</td>\n      <td>0.95272</td>\n      <td>0.86732</td>\n      <td>0.45240</td>\n      <td>0.29545</td>\n      <td>2.5076</td>\n      <td>0.000132</td>\n      <td>0.000132</td>\n      <td>0.000132</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>42</td>\n      <td>0.20593</td>\n      <td>0.21253</td>\n      <td>1.9041</td>\n      <td>0.98457</td>\n      <td>0.93641</td>\n      <td>0.95357</td>\n      <td>0.86813</td>\n      <td>0.45710</td>\n      <td>0.28467</td>\n      <td>2.5179</td>\n      <td>0.000114</td>\n      <td>0.000114</td>\n      <td>0.000114</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>43</td>\n      <td>0.19943</td>\n      <td>0.25987</td>\n      <td>1.8619</td>\n      <td>0.98911</td>\n      <td>0.93182</td>\n      <td>0.94511</td>\n      <td>0.86255</td>\n      <td>0.45248</td>\n      <td>0.29214</td>\n      <td>2.4881</td>\n      <td>0.000096</td>\n      <td>0.000096</td>\n      <td>0.000096</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>44</td>\n      <td>0.19073</td>\n      <td>0.21239</td>\n      <td>1.8758</td>\n      <td>0.99039</td>\n      <td>0.93464</td>\n      <td>0.94798</td>\n      <td>0.86752</td>\n      <td>0.44919</td>\n      <td>0.28252</td>\n      <td>2.5230</td>\n      <td>0.000081</td>\n      <td>0.000081</td>\n      <td>0.000081</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>0.18484</td>\n      <td>0.20205</td>\n      <td>1.8885</td>\n      <td>0.98763</td>\n      <td>0.93480</td>\n      <td>0.95019</td>\n      <td>0.86592</td>\n      <td>0.44724</td>\n      <td>0.28675</td>\n      <td>2.5194</td>\n      <td>0.000067</td>\n      <td>0.000067</td>\n      <td>0.000067</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>46</td>\n      <td>0.18160</td>\n      <td>0.19207</td>\n      <td>1.8845</td>\n      <td>0.98490</td>\n      <td>0.93465</td>\n      <td>0.94868</td>\n      <td>0.86513</td>\n      <td>0.45292</td>\n      <td>0.29405</td>\n      <td>2.5296</td>\n      <td>0.000054</td>\n      <td>0.000054</td>\n      <td>0.000054</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>47</td>\n      <td>0.18038</td>\n      <td>0.19424</td>\n      <td>1.8495</td>\n      <td>0.98927</td>\n      <td>0.93489</td>\n      <td>0.94662</td>\n      <td>0.87385</td>\n      <td>0.44193</td>\n      <td>0.28230</td>\n      <td>2.5060</td>\n      <td>0.000044</td>\n      <td>0.000044</td>\n      <td>0.000044</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>48</td>\n      <td>0.17204</td>\n      <td>0.18580</td>\n      <td>1.8620</td>\n      <td>0.98814</td>\n      <td>0.93477</td>\n      <td>0.94561</td>\n      <td>0.87355</td>\n      <td>0.43602</td>\n      <td>0.28210</td>\n      <td>2.4859</td>\n      <td>0.000035</td>\n      <td>0.000035</td>\n      <td>0.000035</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>49</td>\n      <td>0.16945</td>\n      <td>0.17955</td>\n      <td>1.8630</td>\n      <td>0.98853</td>\n      <td>0.93472</td>\n      <td>0.94627</td>\n      <td>0.87112</td>\n      <td>0.43723</td>\n      <td>0.28163</td>\n      <td>2.5015</td>\n      <td>0.000029</td>\n      <td>0.000029</td>\n      <td>0.000029</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>50</td>\n      <td>0.16202</td>\n      <td>0.17819</td>\n      <td>1.8559</td>\n      <td>0.98728</td>\n      <td>0.93418</td>\n      <td>0.94551</td>\n      <td>0.87090</td>\n      <td>0.43537</td>\n      <td>0.27448</td>\n      <td>2.4845</td>\n      <td>0.000024</td>\n      <td>0.000024</td>\n      <td>0.000024</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:05:10.719070Z","iopub.execute_input":"2024-02-22T12:05:10.719441Z","iopub.status.idle":"2024-02-22T12:05:11.293673Z","shell.execute_reply.started":"2024-02-22T12:05:10.719412Z","shell.execute_reply":"2024-02-22T12:05:11.292902Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Rename all the columns removing all whitespaces\ndf.columns = df.columns.str.replace(' ','')","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:09:22.444598Z","iopub.execute_input":"2024-02-22T12:09:22.444976Z","iopub.status.idle":"2024-02-22T12:09:22.450106Z","shell.execute_reply.started":"2024-02-22T12:09:22.444946Z","shell.execute_reply":"2024-02-22T12:09:22.449111Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.columns.to_list()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:09:35.514259Z","iopub.execute_input":"2024-02-22T12:09:35.514867Z","iopub.status.idle":"2024-02-22T12:09:35.521163Z","shell.execute_reply.started":"2024-02-22T12:09:35.514837Z","shell.execute_reply":"2024-02-22T12:09:35.520240Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['epoch',\n 'train/box_loss',\n 'train/cls_loss',\n 'train/dfl_loss',\n 'metrics/precision(B)',\n 'metrics/recall(B)',\n 'metrics/mAP50(B)',\n 'metrics/mAP50-95(B)',\n 'val/box_loss',\n 'val/cls_loss',\n 'val/dfl_loss',\n 'lr/pg0',\n 'lr/pg1',\n 'lr/pg2']"},"metadata":{}}]},{"cell_type":"code","source":"\nsns.lineplot(data=df,x='epoch',y= 'metrics/mAP50-95(B)')","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:09:54.647312Z","iopub.execute_input":"2024-02-22T12:09:54.648179Z","iopub.status.idle":"2024-02-22T12:09:54.866696Z","shell.execute_reply.started":"2024-02-22T12:09:54.648147Z","shell.execute_reply":"2024-02-22T12:09:54.865797Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='epoch', ylabel='metrics/mAP50-95(B)'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}